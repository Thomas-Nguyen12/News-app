{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72b676da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import hamming_loss, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# This module refers to k-nearest neighbors for multi-label\n",
    "from skmultilearn.adapt import MLkNN\n",
    "\n",
    "## the ARAAM model is a neural network for large scale text classification \n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy.sparse import csr_matrix \n",
    "import re \n",
    "import joblib \n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3292fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/news_project/lib/python3.13/site-packages/sklearn/base.py:440: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# importing the model \n",
    "\n",
    "model = joblib.load('news_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31db8a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the dataset\n",
    "df = pd.read_csv(\"scraped_news.csv\")\n",
    "# Cleaning the dataset \n",
    "\n",
    "preprocessed_data = joblib.load('preprocessed_data.pkl')\n",
    "preprocessed_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c4765e4-fce0-473b-847d-a2c756542ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forming the X and Y...\n",
      "#--------------------\n",
      "#--------------------\n",
      "Shape of X: (1001,)\n",
      "Creating the target variable...\n",
      "Splitting the dataset...\n",
      "Vectorising...\n",
      "Creating the Classifier...\n",
      "Fitting the Classifier...\n",
      "Shape of X_train_tfidf: (800, 24037)\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 219443 stored elements and shape (800, 24037)>\n",
      "  Coords\tValues\n",
      "  (0, 18908)\t0.031158322915683857\n",
      "  (0, 22286)\t0.07489960377912414\n",
      "  (0, 23133)\t0.03413466640297218\n",
      "  (0, 362)\t0.1316465909352914\n",
      "  (0, 18905)\t0.15341058543851022\n",
      "  (0, 11153)\t0.04275950990055421\n",
      "  (0, 22285)\t0.11955229987677626\n",
      "  (0, 12457)\t0.11528208927654543\n",
      "  (0, 15627)\t0.03341852991610167\n",
      "  (0, 3304)\t0.036934125328452305\n",
      "  (0, 8779)\t0.02156564437336592\n",
      "  (0, 19250)\t0.03888723429780967\n",
      "  (0, 18444)\t0.07963143027594767\n",
      "  (0, 13445)\t0.09163940620386554\n",
      "  (0, 20797)\t0.07724210908239554\n",
      "  (0, 15060)\t0.025170348725956308\n",
      "  (0, 3339)\t0.05133504526033659\n",
      "  (0, 15173)\t0.08528442179528824\n",
      "  (0, 19902)\t0.048447514839455516\n",
      "  (0, 13677)\t0.1114414798129759\n",
      "  (0, 15019)\t0.09413353380917881\n",
      "  (0, 23163)\t0.07192849508586965\n",
      "  (0, 19365)\t0.0338097525383639\n",
      "  (0, 2951)\t0.06929870871269592\n",
      "  (0, 19718)\t0.05907474283250728\n",
      "  :\t:\n",
      "  (799, 21195)\t0.2849496034692564\n",
      "  (799, 571)\t0.07494393992105375\n",
      "  (799, 21194)\t0.1381726536801993\n",
      "  (799, 9712)\t0.08927254466839167\n",
      "  (799, 23622)\t0.07530345866999312\n",
      "  (799, 21961)\t0.0959448539418112\n",
      "  (799, 19391)\t0.07929112602799551\n",
      "  (799, 5531)\t0.10751312351079242\n",
      "  (799, 14255)\t0.0949832011564188\n",
      "  (799, 18559)\t0.11346003179328253\n",
      "  (799, 14993)\t0.10290034308208791\n",
      "  (799, 23797)\t0.11589481997564026\n",
      "  (799, 9741)\t0.12184172825813035\n",
      "  (799, 8340)\t0.11865515515399695\n",
      "  (799, 12529)\t0.11346003179328253\n",
      "  (799, 4987)\t0.13022342472297818\n",
      "  (799, 21358)\t0.13022342472297818\n",
      "  (799, 4542)\t0.26044684944595636\n",
      "  (799, 1344)\t0.11128203954693575\n",
      "  (799, 5001)\t0.13617033300546827\n",
      "  (799, 2745)\t0.28910405894063224\n",
      "  (799, 19957)\t0.14455202947031612\n",
      "  (799, 1995)\t0.14455202947031612\n",
      "  (799, 1990)\t0.14455202947031612\n",
      "  (799, 3224)\t0.14455202947031612\n",
      "-------------------------\n",
      "Shape of Y_train: (800, 14)\n",
      "Test predictions:\n",
      "Shape of the predictions: (201, 14)\n",
      "predictions...: <Compressed Sparse Column sparse matrix of dtype 'int64'\n",
      "\twith 1148 stored elements and shape (201, 14)>\n",
      "  Coords\tValues\n",
      "  (0, 0)\t1\n",
      "  (1, 0)\t1\n",
      "  (3, 0)\t1\n",
      "  (4, 0)\t1\n",
      "  (5, 0)\t1\n",
      "  (6, 0)\t1\n",
      "  (7, 0)\t1\n",
      "  (8, 0)\t1\n",
      "  (9, 0)\t1\n",
      "  (10, 0)\t1\n",
      "  (11, 0)\t1\n",
      "  (12, 0)\t1\n",
      "  (13, 0)\t1\n",
      "  (14, 0)\t1\n",
      "  (15, 0)\t1\n",
      "  (16, 0)\t1\n",
      "  (17, 0)\t1\n",
      "  (18, 0)\t1\n",
      "  (19, 0)\t1\n",
      "  (20, 0)\t1\n",
      "  (21, 0)\t1\n",
      "  (22, 0)\t1\n",
      "  (23, 0)\t1\n",
      "  (24, 0)\t1\n",
      "  (25, 0)\t1\n",
      "  :\t:\n",
      "  (119, 9)\t1\n",
      "  (121, 9)\t1\n",
      "  (122, 9)\t1\n",
      "  (125, 9)\t1\n",
      "  (129, 9)\t1\n",
      "  (136, 9)\t1\n",
      "  (137, 9)\t1\n",
      "  (139, 9)\t1\n",
      "  (144, 9)\t1\n",
      "  (149, 9)\t1\n",
      "  (153, 9)\t1\n",
      "  (154, 9)\t1\n",
      "  (159, 9)\t1\n",
      "  (163, 9)\t1\n",
      "  (165, 9)\t1\n",
      "  (167, 9)\t1\n",
      "  (171, 9)\t1\n",
      "  (176, 9)\t1\n",
      "  (178, 9)\t1\n",
      "  (186, 9)\t1\n",
      "  (188, 9)\t1\n",
      "  (194, 9)\t1\n",
      "  (195, 9)\t1\n",
      "  (198, 9)\t1\n",
      "  (199, 9)\t1\n",
      "Accuracy: 0.09950248756218906\n",
      "Weighted f1 score: 0.8046829795345867\n",
      "Weighted Precision: 0.8078845383009464\n",
      "Weighted Recall: 0.8022648083623694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/news_project/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/miniconda3/envs/news_project/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/miniconda3/envs/news_project/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# builidng the model \n",
    "\n",
    "def build_model(data): \n",
    "    \"\"\"\n",
    "    This will be a multi-label classification model \n",
    "    to classify news reports.\n",
    "    \n",
    "    For this, I will use binary relevance as it is a very simple technique\n",
    "    and very interpretable.\n",
    "    \n",
    "    \"\"\"\n",
    "    vectoriser = TfidfVectorizer(stop_words=list(stop_words))\n",
    "    \n",
    "    # vectorising the text \n",
    "    topics = ['Armed conflicts and attacks', 'Arts and culture',\n",
    "       'Business and economy', 'Disasters and accidents',\n",
    "       'Health and environment', 'International relations',\n",
    "       'Law and crime', 'Politics and elections',\n",
    "       'Science and technology', 'Sports', 'Other', 'Royalty',\n",
    "       'Politics and economics', 'Entertainment']\n",
    "    \n",
    "    \n",
    "    # I need to make sure I drop all of the columns \n",
    "    print (\"Forming the X and Y...\")\n",
    "    X = data.text\n",
    "    print (\"#--------------------\")\n",
    "    \n",
    "    print (\"#--------------------\")\n",
    "    \n",
    "    \n",
    "    print (f\"Shape of X: {np.shape(X)}\")\n",
    "    \n",
    "    print (\"Creating the target variable...\")\n",
    "    y = data[[*topics]].values\n",
    "    y = csr_matrix(y, dtype=np.int64)\n",
    "    \n",
    "    # ------ converting y into a matrix \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ------ the vectorizer should be fit on the training dataset first \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print (\"Splitting the dataset...\")\n",
    "    \n",
    "    # ------ Make sure there is a consistent number of samples \n",
    "    # ------ The vectoriser should be fit within the clean dataframe\n",
    "    \n",
    "    # ----- Found input variables with inconsistent numbers of samples: [1001, 14014]\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # ------ Vectorising the training and test dataset \n",
    "    \n",
    "    \n",
    "    print (\"Vectorising...\")\n",
    "    # ------ should only vectorise the training as it prevents data leakge\n",
    "    X_train_tfidf = vectoriser.fit_transform(X_train) \n",
    "    X_test_tfidf = vectoriser.transform(X_test) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print (\"Creating the Classifier...\")\n",
    "    # ------ scipy.sparse does not support dtype object \n",
    "    \n",
    "    classifier = BinaryRelevance(DecisionTreeClassifier())\n",
    "\n",
    "    # train\n",
    "    print (\"Fitting the Classifier...\")\n",
    "    \n",
    "    # ------ Make sure that datatypes of the training and testing are right\n",
    "    # ------ Check datatypes of X_train and Y_train \n",
    "    # ------ make sure the y_train is in int format \n",
    "    \n",
    "    # ------ why is the X train shape (1,1)?\n",
    "    \n",
    "    \n",
    "    print (f\"Shape of X_train_tfidf: {np.shape(X_train_tfidf)}\")\n",
    "    print (X_train_tfidf)\n",
    "    print (\"-------------------------\")\n",
    "    \n",
    "    print (f\"Shape of Y_train: {np.shape(Y_train)}\")\n",
    "    classifier.fit(X_train_tfidf, Y_train)\n",
    "\n",
    "    #    predict\n",
    "    print (\"Test predictions:\") \n",
    "    \n",
    "    predictions = classifier.predict(X_test_tfidf) \n",
    "    print (f\"Shape of the predictions: {np.shape(predictions)}\")\n",
    "    print (f\"predictions...: {predictions}\")\n",
    "    print (f\"Accuracy: {accuracy_score(predictions, Y_test)}\")\n",
    "    print (f\"Weighted f1 score: {f1_score(predictions, Y_test, average=\"weighted\")}\")\n",
    "    print (f\"Weighted Precision: {precision_score(predictions, Y_test, average='weighted')}\")\n",
    "    print (f\"Weighted Recall: {recall_score(predictions, Y_test, average='weighted')}\")\n",
    "    \n",
    "    \n",
    "    # ----- PLOTTING THE CONFUSION MATRIX \n",
    "    print (\"Completed training model\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return classifier, predictions, Y_test, X_test_tfidf\n",
    "\n",
    "\n",
    "model, predictions, Y_test, X_test_tfidf = build_model(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c14ee4f-9062-4294-821b-6202b93b90a3",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e8327b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# performing cross validation \u001b[39;00m\n\u001b[32m      3\u001b[39m k_folds = KFold(n_splits = \u001b[32m5\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m scores = cross_val_score(model, \u001b[43mX\u001b[49m, y, cv = k_folds)\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# performing cross validation \n",
    "# Bear in mind, I need to vectorise the X variable \n",
    "\n",
    "k_folds = KFold(n_splits = 5)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv = k_folds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4c2980-8343-4384-a62e-d6d1a25365ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19a97745-08ff-4fda-9143-d33e30619e3c",
   "metadata": {},
   "source": [
    "# Plotting the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecf8c46d-748d-4255-80ed-cae9715df31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the confusion matrix \n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a0bd0e0-1dea-4f0c-925d-398badb94c43",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BinaryRelevance' object has no attribute 'classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'BinaryRelevance' object has no attribute 'classes_'"
     ]
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891eed2-f32d-41a4-914c-782b62b0b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=model.classes_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
